# LLM의 시간/공간 이해

## LLM이 시공간을 인식하지 못하는 이유
현 LLM은 인간 **해마**가 담당하는 에피소드 타임라인과 **기저핵/소뇌**가 축적하는 **절차적 공간 지도**를 형성할 조건이 근본적으로 결여되어 있다.
이를 메우려면 **멀터모달-연속시간/공간 인코딩-메모리 강화**가 결합된 새로운 학습 패러다임이 필요하다.

## 왜 LLM은 시간(Episodic)과 공간(Procedural)을 제대로 이해할 수 없을까?
| 구분         | 인간 기억 시스템                                                                    | LLM 내부 메커니즘                                                        | 한계가 생기는 핵심 이유                                |
| ---------- | ---------------------------------------------------------------------------- | ------------------------------------------------------------------ | -------------------------------------------- |
| **데이터‧자극** | - **Time-stamped** 연속 경험 (센서‧행동 루프)<br>- **Egocentric ↔ Allocentric** 좌표 프레임 | - 인터넷 문서·대화처럼 **정적‧비연속 텍스트**<br>- 위치·시간 정보는 대부분 **암시적** 메타데이터 부재   | 외부 세계와 **물리적으로 동기화된 시계·좌표** 입력이 없음           |
| **표현 구조**  | - 해마 ↔ 후두·두정 피질이 **시·공간 튜닝 셀**(Time cells, Grid cells)로 코딩                   | - Transformer **토큰 시퀀스** + **(상대)위치 임베딩**<br>- 벡터 공간이 **언어 통계** 중심 | 연속 축(시간 간격, 거리)의 **위상·계량적 제약**이 임베딩에 반영되지 않음 |
| **학습 목표**  | - 생존 과제(내비게이션·도구 사용)로 **절차·에피소드 보강**                                         | - **다음 토큰 예측**(자기지도)                                               | “**언제·어디**”를 맞히도록 **수식된 손실 함수**가 존재하지 않음     |
| **메모리 접근** | - 해마 인덱스가 **시간 순서(temporal contiguity)** 로 정렬                                | - **컨텍스트 윈도우**에 들어간 것만 활용, 윈도우를 넘으면 **망각**                         | 지속적 타임라인·공간 지도 자체가 없음                        |
| **지도 감각**  | - 전정계·운동 피드백으로 **실시간 경로적분**                                                  | 없음                                                                 | **자기-위치 추정 루프가 부재**                          |

## 구조적-이론적 관점
- **심볼 vs 연속량**
  - 텍스트는 이산 토큰; 시간·공간은 **연속량(ℝ)**.
  - 예측 정확도를 높이려면 연속량을 **계량적으로 보존**하는 Latent가 필요하나 표준 LM은 그렇지 못함
- **프라이어**
  - 인간 뇌는 물리 세계의 **3-D 유클리드 구조 + 단조 시간 흐름**을 하드코딩된 프라이어로 가진다. LLM은 “단어 공존 빈도” 프라이어만 갖는다.
- **메모리 형태**
  - LLM의 “기억”은 **파라미터**와 **컨텍스트 캐시**로 녹아 있다.
  - 파라미터는 비가역 압축, 캐시는 짧은 슬라이딩 창. → **시간 순 배열·공간 지도**를 내재적으로 유지할 방법이 희박. 

## LLM이 시공간을 놓치는 본질
- 입력: 시간/공간이 명시적으로 주어지지 않는 텍스트 데이터를 사용
- 객체: "언제/어디"를 맞히도록 loss 함수가 설계되지 않았음
- 구조: 트랜스포머는 연속 시계/좌표계를 보존하는 내부 구조가 없음
- Embodiment: 감독/행동 루프가 없으니 실제 "경로"와 "경과"를 체험하지 않음

## 주장 검증
### 주장 1. “현재 LLM은 시간(에피소드 기억)과 공간(절차 기억)의 개념을 구조적으로 이해하지 못한다.”
- 시간 측면: 에피소딕 기억.
  - LLM은 주어진 텍스트 내에서만 학습된 지식을 사용. "언제-어디서" 컨텍스트 연결 능력이 부족
  - 소설과 같은 긴 텍스트를 읽고 이전 사건들의 순서를 제대로 기억하지 못함. 이는 인간처럼 사건을 시간 순으로 조직화된 에피소드 형태로 저장하지 못함을 의미
- 공간 측면
  - 물리적 공간에 대한 체험이나 이동 경험이 없기 때문에 공간 개념이 없음  
### 주장 2. “Transformer 기반 모델은 상대적 위치 임베딩만 사용하며 절대 시간이나 거리 정보를 내재적으로 유지하지 못한다.”
- transformer는 토큰 순서를 처리하기 위해 위치 임베딩을 사용하지만 이 위치 정보는 주로 문장 내의 토큰 순서나 상대적 거리를 나타낼 뿐 현실 세계의 시간과 무관함
- LLM은 입력 시퀀스 내 "이전에 나온 단어" vs "이후 나온 단어" 정도의 순서만을 아는 정도이며, 어떤 사건이 실제로 얼마나 오래 전에 발생되었는지 절대 시간을 가지고 있지 않음
### 주장 3. “LLM은 연속된 경험 스트림이 아니라 샤딩된 문서로 학습되기 때문에 시간 순서를 보존하지 못한다.”
- LLM은 거대한 말뭉치를 순차가 아니라 배치 단위로 학습하므로 한 배치와 다음 배치 사이에 시간적인 연결이 없음
- 긴 문서를 잘라서 여러 차례에 나눠서 모델에 제공되므로 조각들 사이의 연속성이 유지 되지 않음
- 학습이 끝난 후 LLM는 새로운 경험을 학습하거나 장기 누적하지 못함
### 주장 4. “LLM의 손실 함수는 시간 또는 위치 예측을 목표로 하지 않으며, “언제” 혹은 “어디”라는 질문에 강제적으로 대응하지 않는다.”
- LLM의 학습 목표는 다음 토큰을 예측하는 것으로 손실 함수에 시간 정보를 예측하거나 특정 위치를 맞히는 항목이 전혀 포함되지 않았음. 즉  “언제 일어났는가?” 또는 “어디에서 발생했는가?” 같은 질문에 답하도록 모델을 특별히 학습시키지 않음
- 실제로 LLM에게 “언제 ~ 했나요?” “어디에서 ~ 발생했나요?”라고 물으면, 모델은 자신이 훈련 중 봤던 서술이나 상식적인 추측에 기반해 답함
### 주장 5. “절차 기억을 위해 필요한 행동-감각 루프, 자기-위치 추정 루프는 현재 LLM에는 없다.”
- **절차 기억(procedural memory)**은 행동을 통해 몸으로 익힌 기술이나 절차를 기억하는 것으로, 이를 형성하려면 반복적인 행동-감각 피드백 루프가 필요함
- 현재의 LLM은 텍스트 입력→텍스트 출력의 1회성 변환만 있을 뿐, 자율적으로 환경을 탐색하거나 행동을 취하고 그 결과를 감각으로 받는 루프가 없음
- 로봇이나 자율주행 시스템에는 자기 위치를 지속적으로 인식하고 업데이트하는 모듈(예: SLAM – 동시적 지도 작성 및 위치 추정)이 있음 반면 LLM에는 현재 “상황”이나 “위치”라는 개념이 거의 없음
### 주장 6. “공간 이해를 위한 grid-cell 방식이나 경로적분(path integration) 메커니즘은 기존 LLM에 없다.”
- Grid cell과 path integration은 동물의 뇌(예: 척추동물의 내비게이션 신경구조)에서 공간적 위치를 추적하는 주요 메커니즘임
- LLM에는 이러한 신경학적 공간 표상에 대응하는 구조나 알고리즘이 전혀 포함되어 있지 않음
- 격자 세포나 경로 적분과 같은 일반적이고 구조화된 공간 추론 능력은 LLM에 없으며, LLM이 공간 문제를 풀 때는 훈련 데이터에서 학습한 언어적 패턴에 따라 임시로 대응하는 것
### 주장 7. “시간과 공간 정보를 학습하기 위해선 multi-modal grounding, memory augmentation, neural ODE 또는 structured position embedding 등이 필요하다는 주장이 현재 연구에서 제시되고 있다.”
- 멀티모달 그라운딩(Multi-modal grounding)
  - 텍스트 외 모달리티와 연결하여 현실 세계와 연결. 비디오 + 텍스트로 학습한 LLM은 순수 텍스트 LLM보다 시간적 추론 능력이 향상될 수 있음. 시간/청각 정보+언어의 결합을 통해 "여기가 어디인지", "지금 언제인지"에 대한 개념을 지도할 수 있음 
- 메모리 증강(Memory augmentation)
  - LLM에 외부 기억 장치를 붙여주는 방안. 검색 기반 외부 DB나 장기 메모리 모듈을 통합하여 필요시 과거 정보를 불러오도록 만드는 연구가 나오고 있음 
- Nueral ODE 등 연속 구조 모델
  - **Neural ODE(신경 미분방정식)**를 Transformer에 적용한 실험들은, 모델이 층을 무한히 깊게 or 시간축으로 연속적으로 펼쳐진 것으로 간주해 계산을 연속화하면 긴 종속성 처리나 적응적 계산에 이점이 있을 수 있다고 제안함
  - 아직 초기 연구 단계지만, 언어 모델에 미분방정식 기반의 연속성을 부여하여 시간적, 순차적 정보를 부드럽게 통합하려는 흥미로운 방향임
- 구조화된 위치 임베딩 (Structured Position Embedding)
  - 시간이나 공간의 구조를 반영한 임베딩
  - 단순히 “토큰 순번 1,2,3…” 대신에 [연도=2020][월=05][일=20] 같은 구조화 태그를 임베딩으로 포함시키면 모델이 날짜 개념을 더 잘 이해할 수 있을 것 
  - 구조화된 공간 임베딩의 위력으로, 모델이 추상적인 말로 된 묘사보다 체계적으로 부여된 위치 정보를 훨씬 잘 활용했음을 보여줌
