# LLM의 파국적 망각 위기
## 파국적 망각
- 신경망이 새로운 정보를 학습할 때 이전에 습득한 지식을 갑작스럽게 잃어버리는 현상
- 사전 학습된 LLM을 특정 도메인에 맞게 fine-tuning할 때 심각하게 나타남
- 일부 연구에서는 모델 규모가 커질수록 망각의 정도가 심화될 수 있음을 보여줌

## 파국적 망각의 원인
- 단순히 파라미터를 덮어쓰는 현상을 넘어 더 구조적인 "표현 벙목 현상"에 기인
- 현재 단일 구조 LLM은 통계적 규칙성, 사실적 정보, 절차적 기술 등 모든 조율의 지식을 분화되지 않은 단일 파라미터 공간에 인코딩
- 사전 학습된 LLM의 지식: 세계의 규칙성에 대한 신피질의 이해아 유사한 통계적, 구조적 형태를 띰
- 새로운 fine-tuning 데이터: 특정하고 일화적인 정보를 나타냄
- transformer 구조는 새로운 정보를 기존의 일반 지식을 인코딩하는 동일한 가중치를 직접 수정하여 학습. 표현 수준에서 충돌을 야기
- 특정 정보를 신혹하게 획득하고 임시 저장하여 나중에 통합할 수 있는 전용 하위 시스템의 부재 (e.g. episodic buffer의 부재)

## i-LLM 과 m-LLM 아키텍처 제안
- LLM의 한계가 학습에 내재된 계산적 trade-off를 존중하지 않은 단일 아키텍처로부터 비롯됨
- i-LLM과 m-LLM
- 뇌의 상보적 학습 시스템 이론에 따라 빠른 일화적인 학습과 느리고 구조적인 지식 통합을 기능적으로 분리하여 진정한 평생 학습을 달성하는 것을 목표로 함

# 생물학적 기억에서 계산 모델까지
## 안정성-가소성 딜레마 (Stability-Plasticity Deilemma)
- 모든 학습 시스템은 근본적인 trade-off에 직면하는데 이를 안정성-가소성 딜레마라고 함
- 가소성: 새로운 정보를 습득할 수 있을 만큼 충분히 가소성을 유지해야 함
- 안정성: 기존 지식의 침식을 방지할 수 있을 만큼 충분히 안정성을 유지해야 함

## 상보적 학습 시스템 (Complementary Learning System, CLS)
- 해마 (빠른 학습 시스템): 개별 사건의 구체적인 내용을 신속하고 자동으로 인코딩하는데 특화됨
- 신피질 (느린 학습 시스템): 구조화된 지식과 통계적 규칙성을 점진적으로 습득하는데 특화됨. 일반화에는 이상적이지만 너무 빠르게 학습이 일어나면 파국적 간섭에 매우 취약
- replay를 통한 시스템 수준의 통합
  - 해마는 최근에 저장된 기억을 "재생"하거나, "재활성화"하며 이 정보는 신피질의 학습 데이터로 사용
  - 파국적 망각을 방지하기 위해 이미 알고 있는 다른 정보와 끼워 넣기(interleaving) 방식으로 혼합되어 제공됨. (replay하는 하는 이유... replay를 통해 이전 지식을 다시 상기)
 
## Transformer의 구조적 병목
- 구조적 한계
  - 셀프 어텐션의 제곱 복잡도
  - 순방향 및 비-재귀적 특정
- 
