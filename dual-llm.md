# LLM의 파국적 망각 위기
## 파국적 망각
- 신경망이 새로운 정보를 학습할 때 이전에 습득한 지식을 갑작스럽게 잃어버리는 현상
- 사전 학습된 LLM을 특정 도메인에 맞게 fine-tuning할 때 심각하게 나타남
- 일부 연구에서는 모델 규모가 커질수록 망각의 정도가 심화될 수 있음을 보여줌

## 파국적 망각의 원인
- 단순히 파라미터를 덮어쓰는 현상을 넘어 더 구조적인 "표현 벙목 현상"에 기인
- 현재 단일 구조 LLM은 통계적 규칙성, 사실적 정보, 절차적 기술 등 모든 조율의 지식을 분화되지 않은 단일 파라미터 공간에 인코딩
- 사전 학습된 LLM의 지식: 세계의 규칙성에 대한 신피질의 이해아 유사한 통계적, 구조적 형태를 띰
- 새로운 fine-tuning 데이터: 특정하고 일화적인 정보를 나타냄
- transformer 구조는 새로운 정보를 기존의 일반 지식을 인코딩하는 동일한 가중치를 직접 수정하여 학습. 표현 수준에서 충돌을 야기
- 특정 정보를 신혹하게 획득하고 임시 저장하여 나중에 통합할 수 있는 전용 하위 시스템의 부재 (e.g. episodic buffer의 부재)

## i-LLM 과 m-LLM 아키텍처 제안
- LLM의 한계가 학습에 내재된 계산적 trade-off를 존중하지 않은 단일 아키텍처로부터 비롯됨
- i-LLM과 m-LLM
- 뇌의 상보적 학습 시스템 이론에 따라 빠른 일화적인 학습과 느리고 구조적인 지식 통합을 기능적으로 분리하여 진정한 평생 학습을 달성하는 것을 목표로 함

# 생물학적 기억에서 계산 모델까지
## 안정성-가소성 딜레마 (Stability-Plasticity Deilemma)
- 모든 학습 시스템은 근본적인 trade-off에 직면하는데 이를 안정성-가소성 딜레마라고 함
- 가소성: 새로운 정보를 습득할 수 있을 만큼 충분히 가소성을 유지해야 함
- 안정성: 기존 지식의 침식을 방지할 수 있을 만큼 충분히 안정성을 유지해야 함

## 상보적 학습 시스템 (Complementary Learning System, CLS)
- 해마 (빠른 학습 시스템): 개별 사건의 구체적인 내용을 신속하고 자동으로 인코딩하는데 특화됨
- 신피질 (느린 학습 시스템): 구조화된 지식과 통계적 규칙성을 점진적으로 습득하는데 특화됨. 일반화에는 이상적이지만 너무 빠르게 학습이 일어나면 파국적 간섭에 매우 취약
- replay를 통한 시스템 수준의 통합
  - 해마는 최근에 저장된 기억을 "재생"하거나, "재활성화"하며 이 정보는 신피질의 학습 데이터로 사용
  - 파국적 망각을 방지하기 위해 이미 알고 있는 다른 정보와 끼워 넣기(interleaving) 방식으로 혼합되어 제공됨. (replay하는 하는 이유... replay를 통해 이전 지식을 다시 상기)
 
## Transformer의 구조적 병목
- 구조적 한계
  - 셀프 어텐션의 제곱 복잡도
  - 순방향 및 비-재귀적 특정
- Transformer의 밀집된 전역적 어텐션은 컨텍스트 혼합과 간섭을 극대화하도록 설계 (--> 순수하게 "신피질"적인 아키텍처)
- 파국적 망각은 신피질적 도구에 해마의 역할을 수행하도록 강요하기 때문에 예측한 결과임 (--> 제안하는 아키텍처는 m-LLM을 도입하여 이 불균형을 해결)

# 지식 증강 및 지속 학습의 현행 패러다임에 대한 비판적 검토
- Dual LLM은 **동적이고 양방향적인 통합 루프**임
- 파라미터 중심의 CL은 해마의 완충 역할을 무시한 채 신피질 유사체에 직접 안정성을 강요하는 신피질 해킹임
- 
## 파라미터 중심의 지속 학습
- 정규화 기반 방법
- 파라미터 분리 방법
## 기억 증강 신경망 (Memory-Augmented Neural Networks, MANNs)
- 높은 학습 복잡도, 대용량 메모리에서 확장성 문제, 메모리 경합 등 심각한 도전에 직면
- 이들의 메모리는 종종 일반적이고 비구조적인 행렬로 복잡한 추론에 필요한 풍부한 관계형 구조가 부족함
- LLM의 규모와 복잡성에는 실용적이지 않음
## 검색 증강 생성 (Retrieval Augmented Generation, RAG)
- 검색 모듈과 LLM을 결합함
- 비판 및 실패 모드: loosely-coupled & read-only 메모리 시스템으로 다음과 가튼 심각한 결함을 가지고 있음
  - 검색 품질: 검색 결과에 잡음이 많거나, 관련성이 없거나, 오래된 정보일수록 생성 품질을 저하시킴
  - 근거 충실도 및 환각: 정확한 정보를 제공하였음에도 불구하고 검색된 컨텍스트를 무시하거나, 잘못 해석하거나, 부정확하게 종합하여 환각을 발생시킬 수 있음
  - 추론 한계: 벡터 기반 검색은 평면적으로 multi-hop 질문에 취약. 시스템은 사실들 간의 관계를 이해하지 못함
  - 통합 부재: 일시적인 cheating paper. 검색된 정보로부터 지속적이고 파라미터적인 방식으로 '학습'하지 않음

# LLM을 위한 해마-신피질 시스템
| 생물학적 유사체 | 구성 요소 | 주요 기능 | 학습 속도 | 표현 스타일 | 핵심 메커니즘 | CLS 루프 내 역할 | 
|---|---|---|---|---|---|---|
| 해마 | mLLM | 새로운 정보의 신속한 획득 및 구조화 | 빠름 | 희소, 구조적 | 일화적 버퍼, 증분적 KG 구성 | 새로운 경험을 포착하고 통합을 위해 재생 |
| 신피질 | iLLM | 복잡한 추론, 이해, 자연어 생성 | 느림 | 밀집, 분산(파라미터) | 적응형 질의, 끼워넣기 fine-tuning | 재생된 경험을 점진적으로 학습하여 일반화| 

## mLLM: 이중 모드 일화 및 의미 기억 저장소
- 새로운 정보를 신속하게 획득하고, 견고한 검색과 통합을 위해 점진적으로 구조화
- **구성 요소 1: 일화적 버퍼 (빠른, 비구조적 학습)**
  - 사용자 대화, 뉴스 기사, 데이터 피드와 같은 원시적이고 타임스탬프가 찍힌 정보 스트림을 포착하는 추가 전용 로그
  - 새로운 일화를 신속하고 자동으로 인코딩하는 해마의 기능을 직접적으로 모델링 
- **구성 요소 2: 구조화된 지식 코어 (느린, 구조적 통합)**
  - 동적 **지식 그래프**를 제안
  - 자체 LLM 능력을 활용. 일화적 버퍼의 내용을 정보 추출하여 비구조적 텍스트를 구조화(주어, 술어, 목적어) 트리플로 변환
  - 지식 그래프는 구조화된 의미론적 장기 기억을 나타냄
- **메커니즘: 에이전트적 실시간 업데이트 메커니즘을 채택함**
  - 새로운 정보가 도착하면, 이를 사용하여 새로운 노드/관계를 생성하거나 기존의 것을 업데이트 

## iLLM: 추론 및 상호작용 엔진
- 주된 사용자 인터페이스로서 복잡한 추론, 이해, 자연어 생성을 수행
- 강력하고 범용적인 사전 학습된 LLM으로 초기화
- **메커니즘: 적응형 질의 프로토콜**
  - iLLM은 mLLM과 상호작용하는 법을 학습
  - 주어진 사용자 질의에 대해 iLLM은 먼저 자신의 파라미터 지식으로 답변할 수 있는지 평가
  - 만약 불가능하다면, 문제를 분해하고 mLLM의 지식 그래프에 대한 구조화된 질의를 생성
  - mLLM은 관련 하위 그래프나 사실 집합을 반환. iLLM은 이를 종합하여 일관성 있고 근거 있으며 설명 가능한 답변을 생성함
 
## 통합 루프: 시스템 수준의 기억 재생 시뮬레이션
- mLLM으로부터 검증된 새로운 지식을 iLLM의 파라미터 가중치에 안정적으로 통합하여 진정한 장기 학습과 일반화를 가능
- **메커니즘**
  - 샘플링: 시스템은 mLLM에서 지식 그래프(KG)로 구조화된 지식을 샘플링함
  - 학습 데이터 생성: 샘플링된 KG 조각들은 자연어 학습 예(e.g. 질문-답변 쌍, 사실적 진술)로 변환
  - 끼어넣기 fine-tuning: iLLM은 이 재생된 예제와 일화적 버퍼의 소량의 새로운 데이터로 구성된 혼합 데이터셋에 대해 PEFT(e.g. LoRA)을 사용하여 미세 조정됨
  - 이 단계를 통해 mLLM의 특정하고 일화적인 지식을 iLLM의 파라미터 내 일반화된 통계적 지식으로 변환함



